<!DOCTYPE html><html lang="en" class="dark"><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width, initial-scale=1"/><link rel="preload" href="/aidailynews/_next/static/media/e4af272ccee01ff0-s.p.woff2" as="font" crossorigin="" type="font/woff2"/><link rel="stylesheet" href="/aidailynews/_next/static/css/cd31037e105c8179.css" data-precedence="next"/><link rel="preload" as="script" fetchPriority="low" href="/aidailynews/_next/static/chunks/webpack-00a2686bd3fa7556.js"/><script src="/aidailynews/_next/static/chunks/fd9d1056-8042ad09b3c311e2.js" async=""></script><script src="/aidailynews/_next/static/chunks/23-fd109d2e6bdc4bd5.js" async=""></script><script src="/aidailynews/_next/static/chunks/main-app-47a76ebf2a722873.js" async=""></script><script src="/aidailynews/_next/static/chunks/231-0a45a70fc661b993.js" async=""></script><script src="/aidailynews/_next/static/chunks/app/guides/local-llm-integration/page-5634af547cee0dd2.js" async=""></script><title>Local LLM Integration | AI Daily News</title><meta name="description" content="Guide on connecting OpenClaw with local language models using Ollama and LM Studio."/><meta name="author" content="AI Daily News"/><meta name="keywords" content="AI news,artificial intelligence,machine learning,GPT,OpenAI,tech news"/><meta name="robots" content="index, follow"/><meta property="og:title" content="AI Daily News"/><meta property="og:description" content="Daily curated AI news and breakthroughs"/><meta property="og:site_name" content="AI Daily News"/><meta property="og:type" content="website"/><meta name="twitter:card" content="summary_large_image"/><meta name="twitter:title" content="AI Daily News"/><meta name="twitter:description" content="Daily curated AI news and breakthroughs"/><meta name="next-size-adjust"/><script type="application/ld+json">{"@context":"https://schema.org","@type":"WebSite","name":"AI Daily News","url":"https://aidailynews.org","description":"Daily curated artificial intelligence news","publisher":{"@type":"Organization","name":"AI Daily News"}}</script><script src="/aidailynews/_next/static/chunks/polyfills-78c92fac7aa8fdd8.js" noModule=""></script></head><body class="__className_734aab bg-gray-900 text-gray-100"><div class="min-h-screen bg-gray-900"><header class="bg-gray-900 border-b border-gray-800 sticky top-0 z-50"><div class="max-w-7xl mx-auto px-4 sm:px-6 lg:px-8"><div class="flex items-center justify-between h-16"><a class="flex items-center space-x-2" href="/aidailynews/"><div class="w-8 h-8 bg-gradient-to-br from-blue-500 to-purple-600 rounded-lg flex items-center justify-center"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-bot w-5 h-5 text-white"><path d="M12 8V4H8"></path><rect width="16" height="12" x="4" y="8" rx="2"></rect><path d="M2 14h2"></path><path d="M20 14h2"></path><path d="M15 13v2"></path><path d="M9 13v2"></path></svg></div><span class="text-xl font-bold bg-gradient-to-r from-blue-400 to-purple-400 bg-clip-text text-transparent">AI Daily News</span></a><a class="flex items-center text-gray-400 hover:text-white transition-colors" href="/aidailynews/guides/"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-arrow-left w-4 h-4 mr-2"><path d="m12 19-7-7 7-7"></path><path d="M19 12H5"></path></svg>Back to Guides</a></div></div></header><main class="max-w-4xl mx-auto px-4 py-12"><div class="flex items-center space-x-3 mb-8"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-code w-8 h-8 text-green-400"><polyline points="16 18 22 12 16 6"></polyline><polyline points="8 6 2 12 8 18"></polyline></svg><h1 class="text-4xl font-bold text-white">Local LLM Integration</h1></div><p class="text-xl text-gray-400 mb-8 max-w-3xl">Connect OpenClaw with local language models using Ollama and LM Studio for privacy and cost savings.</p><article class="prose prose-invert max-w-none"><h2 class="text-2xl font-bold text-white mt-8 mb-4">Introduction</h2><p class="text-gray-300">While cloud-based AI models offer immense power, running them locally provides benefits like enhanced privacy, reduced costs, and faster inference times for certain tasks. This guide shows you how to integrate OpenClaw with popular local LLM solutions like Ollama and LM Studio.</p><h2 class="text-2xl font-bold text-white mt-8 mb-4">Why Local LLMs?</h2><ul class="text-gray-300 space-y-2"><li><strong class="text-white">Privacy:</strong> Your data never leaves your machine. Ideal for sensitive code or personal information.</li><li><strong class="text-white">Cost Savings:</strong> Eliminates API call fees, especially beneficial for heavy usage.</li><li><strong class="text-white">Speed:</strong> Can offer lower latency once loaded, particularly for non-cloud-optimized models.</li><li><strong class="text-white">Customization:</strong> Allows fine-tuning models for specific tasks and preferences.</li></ul><h2 class="text-2xl font-bold text-white mt-8 mb-4">Option 1: Using Ollama</h2><p class="text-gray-300">Ollama simplifies running large language models locally.</p><ol class="text-gray-300 space-y-3"><li><strong class="text-white">Install Ollama:</strong> Download and install Ollama from <a target="_blank" rel="noopener noreferrer" class="text-blue-400 hover:underline" href="https://ollama.ai/">ollama.ai</a>.</li><li><strong class="text-white">Download a Model:</strong> Open your terminal and pull a model, for example, Llama 3:<pre class="bg-gray-800 text-gray-300 p-4 rounded-lg overflow-x-auto my-4"><code>ollama pull llama3</code></pre></li><li><strong class="text-white">Configure OpenClaw:</strong>In your OpenClaw configuration (e.g., `openclaw.json` or similar), point OpenClaw&#x27;s local model setting to your Ollama endpoint. This typically involves setting an environment variable or a config option like:<pre class="bg-gray-800 text-gray-300 p-4 rounded-lg overflow-x-auto my-4"><code>OPENCLAW_LOCAL_LLM_ENDPOINT=http://localhost:11434</code></pre>(Check OpenClaw&#x27;s documentation for the exact configuration method.)</li></ol><h2 class="text-2xl font-bold text-white mt-8 mb-4">Option 2: Using LM Studio</h2><p class="text-gray-300">LM Studio provides a GUI for downloading and running LLMs locally.</p><ol class="text-gray-300 space-y-3"><li><strong class="text-white">Install LM Studio:</strong> Download and install LM Studio from <a target="_blank" rel="noopener noreferrer" class="text-blue-400 hover:underline" href="https://lmstudio.ai/">lmstudio.ai</a>.</li><li><strong class="text-white">Download a Model:</strong> Use the LM Studio UI to search for and download a model (e.g., Mistral 7B Instruct).</li><li><strong class="text-white">Start the Local Server:</strong> In LM Studio, navigate to the &quot;Local Server&quot; tab and start the server. Note the local API endpoint (usually `http://localhost:1234`).</li><li><strong class="text-white">Configure OpenClaw:</strong> Similar to Ollama, point OpenClaw&#x27;s local model setting to the LM Studio server endpoint.</li></ol><h2 class="text-2xl font-bold text-white mt-8 mb-4">Important Considerations</h2><ul class="text-gray-300 space-y-2"><li><strong class="text-white">Hardware Requirements:</strong> Running LLMs locally requires significant RAM and often a capable GPU. Check the model&#x27;s requirements.</li><li><strong class="text-white">Model Performance:</strong> Local models may not perform as well as top-tier cloud models for all tasks. Experiment to find models that fit your needs.</li><li><strong class="text-white">OpenClaw Documentation:</strong> Always refer to the official OpenClaw documentation for the most up-to-date configuration details for local LLM integration.</li></ul></article></main><footer class="bg-gray-900 border-t border-gray-800 mt-12"><div class="max-w-7xl mx-auto px-4 py-8"><p class="text-center text-gray-500 text-sm">© 2026 AI Daily News. Built with OpenClaw.</p></div></footer></div><script src="/aidailynews/_next/static/chunks/webpack-00a2686bd3fa7556.js" async=""></script><script>(self.__next_f=self.__next_f||[]).push([0]);self.__next_f.push([2,null])</script><script>self.__next_f.push([1,"1:HL[\"/aidailynews/_next/static/media/e4af272ccee01ff0-s.p.woff2\",\"font\",{\"crossOrigin\":\"\",\"type\":\"font/woff2\"}]\n2:HL[\"/aidailynews/_next/static/css/cd31037e105c8179.css\",\"style\"]\n"])</script><script>self.__next_f.push([1,"3:I[5751,[],\"\"]\n5:I[231,[\"231\",\"static/chunks/231-0a45a70fc661b993.js\",\"484\",\"static/chunks/app/guides/local-llm-integration/page-5634af547cee0dd2.js\"],\"\"]\n6:I[9275,[],\"\"]\n7:I[1343,[],\"\"]\n9:I[6130,[],\"\"]\na:[]\n"])</script><script>self.__next_f.push([1,"0:[[[\"$\",\"link\",\"0\",{\"rel\":\"stylesheet\",\"href\":\"/aidailynews/_next/static/css/cd31037e105c8179.css\",\"precedence\":\"next\",\"crossOrigin\":\"$undefined\"}]],[\"$\",\"$L3\",null,{\"buildId\":\"QdGtS8K4ksokWSIvJZMAK\",\"assetPrefix\":\"/aidailynews\",\"initialCanonicalUrl\":\"/guides/local-llm-integration/\",\"initialTree\":[\"\",{\"children\":[\"guides\",{\"children\":[\"local-llm-integration\",{\"children\":[\"__PAGE__\",{}]}]}]},\"$undefined\",\"$undefined\",true],\"initialSeedData\":[\"\",{\"children\":[\"guides\",{\"children\":[\"local-llm-integration\",{\"children\":[\"__PAGE__\",{},[[\"$L4\",[\"$\",\"div\",null,{\"className\":\"min-h-screen bg-gray-900\",\"children\":[[\"$\",\"header\",null,{\"className\":\"bg-gray-900 border-b border-gray-800 sticky top-0 z-50\",\"children\":[\"$\",\"div\",null,{\"className\":\"max-w-7xl mx-auto px-4 sm:px-6 lg:px-8\",\"children\":[\"$\",\"div\",null,{\"className\":\"flex items-center justify-between h-16\",\"children\":[[\"$\",\"$L5\",null,{\"href\":\"/\",\"className\":\"flex items-center space-x-2\",\"children\":[[\"$\",\"div\",null,{\"className\":\"w-8 h-8 bg-gradient-to-br from-blue-500 to-purple-600 rounded-lg flex items-center justify-center\",\"children\":[\"$\",\"svg\",null,{\"xmlns\":\"http://www.w3.org/2000/svg\",\"width\":24,\"height\":24,\"viewBox\":\"0 0 24 24\",\"fill\":\"none\",\"stroke\":\"currentColor\",\"strokeWidth\":2,\"strokeLinecap\":\"round\",\"strokeLinejoin\":\"round\",\"className\":\"lucide lucide-bot w-5 h-5 text-white\",\"children\":[[\"$\",\"path\",\"hb8ula\",{\"d\":\"M12 8V4H8\"}],[\"$\",\"rect\",\"enze0r\",{\"width\":\"16\",\"height\":\"12\",\"x\":\"4\",\"y\":\"8\",\"rx\":\"2\"}],[\"$\",\"path\",\"vft8re\",{\"d\":\"M2 14h2\"}],[\"$\",\"path\",\"4cs60a\",{\"d\":\"M20 14h2\"}],[\"$\",\"path\",\"1xurst\",{\"d\":\"M15 13v2\"}],[\"$\",\"path\",\"rq6x2g\",{\"d\":\"M9 13v2\"}],\"$undefined\"]}]}],[\"$\",\"span\",null,{\"className\":\"text-xl font-bold bg-gradient-to-r from-blue-400 to-purple-400 bg-clip-text text-transparent\",\"children\":\"AI Daily News\"}]]}],[\"$\",\"$L5\",null,{\"href\":\"/guides/\",\"className\":\"flex items-center text-gray-400 hover:text-white transition-colors\",\"children\":[[\"$\",\"svg\",null,{\"xmlns\":\"http://www.w3.org/2000/svg\",\"width\":24,\"height\":24,\"viewBox\":\"0 0 24 24\",\"fill\":\"none\",\"stroke\":\"currentColor\",\"strokeWidth\":2,\"strokeLinecap\":\"round\",\"strokeLinejoin\":\"round\",\"className\":\"lucide lucide-arrow-left w-4 h-4 mr-2\",\"children\":[[\"$\",\"path\",\"1l729n\",{\"d\":\"m12 19-7-7 7-7\"}],[\"$\",\"path\",\"x3x0zl\",{\"d\":\"M19 12H5\"}],\"$undefined\"]}],\"Back to Guides\"]}]]}]}]}],[\"$\",\"main\",null,{\"className\":\"max-w-4xl mx-auto px-4 py-12\",\"children\":[[\"$\",\"div\",null,{\"className\":\"flex items-center space-x-3 mb-8\",\"children\":[[\"$\",\"svg\",null,{\"xmlns\":\"http://www.w3.org/2000/svg\",\"width\":24,\"height\":24,\"viewBox\":\"0 0 24 24\",\"fill\":\"none\",\"stroke\":\"currentColor\",\"strokeWidth\":2,\"strokeLinecap\":\"round\",\"strokeLinejoin\":\"round\",\"className\":\"lucide lucide-code w-8 h-8 text-green-400\",\"children\":[[\"$\",\"polyline\",\"z7tu5w\",{\"points\":\"16 18 22 12 16 6\"}],[\"$\",\"polyline\",\"1eg1df\",{\"points\":\"8 6 2 12 8 18\"}],\"$undefined\"]}],[\"$\",\"h1\",null,{\"className\":\"text-4xl font-bold text-white\",\"children\":\"Local LLM Integration\"}]]}],[\"$\",\"p\",null,{\"className\":\"text-xl text-gray-400 mb-8 max-w-3xl\",\"children\":\"Connect OpenClaw with local language models using Ollama and LM Studio for privacy and cost savings.\"}],[\"$\",\"article\",null,{\"className\":\"prose prose-invert max-w-none\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"text-2xl font-bold text-white mt-8 mb-4\",\"children\":\"Introduction\"}],[\"$\",\"p\",null,{\"className\":\"text-gray-300\",\"children\":\"While cloud-based AI models offer immense power, running them locally provides benefits like enhanced privacy, reduced costs, and faster inference times for certain tasks. This guide shows you how to integrate OpenClaw with popular local LLM solutions like Ollama and LM Studio.\"}],[\"$\",\"h2\",null,{\"className\":\"text-2xl font-bold text-white mt-8 mb-4\",\"children\":\"Why Local LLMs?\"}],[\"$\",\"ul\",null,{\"className\":\"text-gray-300 space-y-2\",\"children\":[[\"$\",\"li\",null,{\"children\":[[\"$\",\"strong\",null,{\"className\":\"text-white\",\"children\":\"Privacy:\"}],\" Your data never leaves your machine. Ideal for sensitive code or personal information.\"]}],[\"$\",\"li\",null,{\"children\":[[\"$\",\"strong\",null,{\"className\":\"text-white\",\"children\":\"Cost Savings:\"}],\" Eliminates API call fees, especially beneficial for heavy usage.\"]}],[\"$\",\"li\",null,{\"children\":[[\"$\",\"strong\",null,{\"className\":\"text-white\",\"children\":\"Speed:\"}],\" Can offer lower latency once loaded, particularly for non-cloud-optimized models.\"]}],[\"$\",\"li\",null,{\"children\":[[\"$\",\"strong\",null,{\"className\":\"text-white\",\"children\":\"Customization:\"}],\" Allows fine-tuning models for specific tasks and preferences.\"]}]]}],[\"$\",\"h2\",null,{\"className\":\"text-2xl font-bold text-white mt-8 mb-4\",\"children\":\"Option 1: Using Ollama\"}],[\"$\",\"p\",null,{\"className\":\"text-gray-300\",\"children\":\"Ollama simplifies running large language models locally.\"}],[\"$\",\"ol\",null,{\"className\":\"text-gray-300 space-y-3\",\"children\":[[\"$\",\"li\",null,{\"children\":[[\"$\",\"strong\",null,{\"className\":\"text-white\",\"children\":\"Install Ollama:\"}],\" Download and install Ollama from \",[\"$\",\"$L5\",null,{\"href\":\"https://ollama.ai/\",\"target\":\"_blank\",\"rel\":\"noopener noreferrer\",\"className\":\"text-blue-400 hover:underline\",\"children\":\"ollama.ai\"}],\".\"]}],[\"$\",\"li\",null,{\"children\":[[\"$\",\"strong\",null,{\"className\":\"text-white\",\"children\":\"Download a Model:\"}],\" Open your terminal and pull a model, for example, Llama 3:\",[\"$\",\"pre\",null,{\"className\":\"bg-gray-800 text-gray-300 p-4 rounded-lg overflow-x-auto my-4\",\"children\":[\"$\",\"code\",null,{\"children\":\"ollama pull llama3\"}]}]]}],[\"$\",\"li\",null,{\"children\":[[\"$\",\"strong\",null,{\"className\":\"text-white\",\"children\":\"Configure OpenClaw:\"}],\"In your OpenClaw configuration (e.g., `openclaw.json` or similar), point OpenClaw's local model setting to your Ollama endpoint. This typically involves setting an environment variable or a config option like:\",[\"$\",\"pre\",null,{\"className\":\"bg-gray-800 text-gray-300 p-4 rounded-lg overflow-x-auto my-4\",\"children\":[\"$\",\"code\",null,{\"children\":\"OPENCLAW_LOCAL_LLM_ENDPOINT=http://localhost:11434\"}]}],\"(Check OpenClaw's documentation for the exact configuration method.)\"]}]]}],[\"$\",\"h2\",null,{\"className\":\"text-2xl font-bold text-white mt-8 mb-4\",\"children\":\"Option 2: Using LM Studio\"}],[\"$\",\"p\",null,{\"className\":\"text-gray-300\",\"children\":\"LM Studio provides a GUI for downloading and running LLMs locally.\"}],[\"$\",\"ol\",null,{\"className\":\"text-gray-300 space-y-3\",\"children\":[[\"$\",\"li\",null,{\"children\":[[\"$\",\"strong\",null,{\"className\":\"text-white\",\"children\":\"Install LM Studio:\"}],\" Download and install LM Studio from \",[\"$\",\"$L5\",null,{\"href\":\"https://lmstudio.ai/\",\"target\":\"_blank\",\"rel\":\"noopener noreferrer\",\"className\":\"text-blue-400 hover:underline\",\"children\":\"lmstudio.ai\"}],\".\"]}],[\"$\",\"li\",null,{\"children\":[[\"$\",\"strong\",null,{\"className\":\"text-white\",\"children\":\"Download a Model:\"}],\" Use the LM Studio UI to search for and download a model (e.g., Mistral 7B Instruct).\"]}],[\"$\",\"li\",null,{\"children\":[[\"$\",\"strong\",null,{\"className\":\"text-white\",\"children\":\"Start the Local Server:\"}],\" In LM Studio, navigate to the \\\"Local Server\\\" tab and start the server. Note the local API endpoint (usually `http://localhost:1234`).\"]}],[\"$\",\"li\",null,{\"children\":[[\"$\",\"strong\",null,{\"className\":\"text-white\",\"children\":\"Configure OpenClaw:\"}],\" Similar to Ollama, point OpenClaw's local model setting to the LM Studio server endpoint.\"]}]]}],[\"$\",\"h2\",null,{\"className\":\"text-2xl font-bold text-white mt-8 mb-4\",\"children\":\"Important Considerations\"}],[\"$\",\"ul\",null,{\"className\":\"text-gray-300 space-y-2\",\"children\":[[\"$\",\"li\",null,{\"children\":[[\"$\",\"strong\",null,{\"className\":\"text-white\",\"children\":\"Hardware Requirements:\"}],\" Running LLMs locally requires significant RAM and often a capable GPU. Check the model's requirements.\"]}],[\"$\",\"li\",null,{\"children\":[[\"$\",\"strong\",null,{\"className\":\"text-white\",\"children\":\"Model Performance:\"}],\" Local models may not perform as well as top-tier cloud models for all tasks. Experiment to find models that fit your needs.\"]}],[\"$\",\"li\",null,{\"children\":[[\"$\",\"strong\",null,{\"className\":\"text-white\",\"children\":\"OpenClaw Documentation:\"}],\" Always refer to the official OpenClaw documentation for the most up-to-date configuration details for local LLM integration.\"]}]]}]]}]]}],[\"$\",\"footer\",null,{\"className\":\"bg-gray-900 border-t border-gray-800 mt-12\",\"children\":[\"$\",\"div\",null,{\"className\":\"max-w-7xl mx-auto px-4 py-8\",\"children\":[\"$\",\"p\",null,{\"className\":\"text-center text-gray-500 text-sm\",\"children\":\"© 2026 AI Daily News. Built with OpenClaw.\"}]}]}]]}]],null],null]},[\"$\",\"$L6\",null,{\"parallelRouterKey\":\"children\",\"segmentPath\":[\"children\",\"guides\",\"children\",\"local-llm-integration\",\"children\"],\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L7\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":\"$undefined\",\"notFoundStyles\":\"$undefined\",\"styles\":null}],null]},[\"$\",\"$L6\",null,{\"parallelRouterKey\":\"children\",\"segmentPath\":[\"children\",\"guides\",\"children\"],\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L7\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":\"$undefined\",\"notFoundStyles\":\"$undefined\",\"styles\":null}],null]},[[\"$\",\"html\",null,{\"lang\":\"en\",\"className\":\"dark\",\"children\":[[\"$\",\"head\",null,{\"children\":[\"$\",\"script\",null,{\"type\":\"application/ld+json\",\"dangerouslySetInnerHTML\":{\"__html\":\"{\\\"@context\\\":\\\"https://schema.org\\\",\\\"@type\\\":\\\"WebSite\\\",\\\"name\\\":\\\"AI Daily News\\\",\\\"url\\\":\\\"https://aidailynews.org\\\",\\\"description\\\":\\\"Daily curated artificial intelligence news\\\",\\\"publisher\\\":{\\\"@type\\\":\\\"Organization\\\",\\\"name\\\":\\\"AI Daily News\\\"}}\"}}]}],[\"$\",\"body\",null,{\"className\":\"__className_734aab bg-gray-900 text-gray-100\",\"children\":[\"$\",\"$L6\",null,{\"parallelRouterKey\":\"children\",\"segmentPath\":[\"children\"],\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L7\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":[[\"$\",\"title\",null,{\"children\":\"404: This page could not be found.\"}],[\"$\",\"div\",null,{\"style\":{\"fontFamily\":\"system-ui,\\\"Segoe UI\\\",Roboto,Helvetica,Arial,sans-serif,\\\"Apple Color Emoji\\\",\\\"Segoe UI Emoji\\\"\",\"height\":\"100vh\",\"textAlign\":\"center\",\"display\":\"flex\",\"flexDirection\":\"column\",\"alignItems\":\"center\",\"justifyContent\":\"center\"},\"children\":[\"$\",\"div\",null,{\"children\":[[\"$\",\"style\",null,{\"dangerouslySetInnerHTML\":{\"__html\":\"body{color:#000;background:#fff;margin:0}.next-error-h1{border-right:1px solid rgba(0,0,0,.3)}@media (prefers-color-scheme:dark){body{color:#fff;background:#000}.next-error-h1{border-right:1px solid rgba(255,255,255,.3)}}\"}}],[\"$\",\"h1\",null,{\"className\":\"next-error-h1\",\"style\":{\"display\":\"inline-block\",\"margin\":\"0 20px 0 0\",\"padding\":\"0 23px 0 0\",\"fontSize\":24,\"fontWeight\":500,\"verticalAlign\":\"top\",\"lineHeight\":\"49px\"},\"children\":\"404\"}],[\"$\",\"div\",null,{\"style\":{\"display\":\"inline-block\"},\"children\":[\"$\",\"h2\",null,{\"style\":{\"fontSize\":14,\"fontWeight\":400,\"lineHeight\":\"49px\",\"margin\":0},\"children\":\"This page could not be found.\"}]}]]}]}]],\"notFoundStyles\":[],\"styles\":null}]}]]}],null],null],\"couldBeIntercepted\":false,\"initialHead\":[false,\"$L8\"],\"globalErrorComponent\":\"$9\",\"missingSlots\":\"$Wa\"}]]\n"])</script><script>self.__next_f.push([1,"8:[[\"$\",\"meta\",\"0\",{\"name\":\"viewport\",\"content\":\"width=device-width, initial-scale=1\"}],[\"$\",\"meta\",\"1\",{\"charSet\":\"utf-8\"}],[\"$\",\"title\",\"2\",{\"children\":\"Local LLM Integration | AI Daily News\"}],[\"$\",\"meta\",\"3\",{\"name\":\"description\",\"content\":\"Guide on connecting OpenClaw with local language models using Ollama and LM Studio.\"}],[\"$\",\"meta\",\"4\",{\"name\":\"author\",\"content\":\"AI Daily News\"}],[\"$\",\"meta\",\"5\",{\"name\":\"keywords\",\"content\":\"AI news,artificial intelligence,machine learning,GPT,OpenAI,tech news\"}],[\"$\",\"meta\",\"6\",{\"name\":\"robots\",\"content\":\"index, follow\"}],[\"$\",\"meta\",\"7\",{\"property\":\"og:title\",\"content\":\"AI Daily News\"}],[\"$\",\"meta\",\"8\",{\"property\":\"og:description\",\"content\":\"Daily curated AI news and breakthroughs\"}],[\"$\",\"meta\",\"9\",{\"property\":\"og:site_name\",\"content\":\"AI Daily News\"}],[\"$\",\"meta\",\"10\",{\"property\":\"og:type\",\"content\":\"website\"}],[\"$\",\"meta\",\"11\",{\"name\":\"twitter:card\",\"content\":\"summary_large_image\"}],[\"$\",\"meta\",\"12\",{\"name\":\"twitter:title\",\"content\":\"AI Daily News\"}],[\"$\",\"meta\",\"13\",{\"name\":\"twitter:description\",\"content\":\"Daily curated AI news and breakthroughs\"}],[\"$\",\"meta\",\"14\",{\"name\":\"next-size-adjust\"}]]\n4:null\n"])</script></body></html>